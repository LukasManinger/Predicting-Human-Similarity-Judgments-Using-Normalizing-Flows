# Poster References

1. Jozwik, K. M., Kriegeskorte, N., Storrs, K. R., & Mur, M. (2017). Deep convolutional neural networks outperform feature-based but not categorical models in explaining object similarity judgments. *Frontiers in Psychology*, 8, 1726. https://doi.org/10.3389/fpsyg.2017.01726.
2. Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The unreasonable effectiveness of deep features as a perceptual metric. https://doi.org/10.48550/arXiv.1801.03924.
3. Roads, B. D., & Love, B. C. (2020). Enriching ImageNet with human similarity judgments and psychological embeddings. https://doi.org/10.48550/arXiv.2011.11015.
4. Jozwik, K. M., O’Keeffe, J., Storrs, K. R., Guo, W., Golan, T., & Kriegeskorte, N. (2022). Face dissimilarity judgments are predicted by representational distance in morphable and image-computable models. *Proceedings of the National Academy of Sciences of the United States of America*, 119(27), e2115047119. https://doi.org/10.1073/pnas.2115047119.
5. Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., & Chen, M. (2022). Hierarchical text-conditional image generation with CLIP latents. https://doi.org/10.48550/arXiv.2204.06125.
6. Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour, S. K. S., Ayan, B. K., Mahdavi, S. S., Lopes, R. G., Salimans, T., Ho, J., Fleet, D. J., & Norouzi, M. (2022). Photorealistic text-to-image diffusion models with deep language understanding. https://doi.org/10.48550/arXiv.2205.11487.
7. Ledig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. Retrieved October 7, 2022, from http://arxiv.org/abs/1609.04802.
8. Papamakarios, G., Nalisnick, E., Rezende, D. J., Mohamed, S., & Lakshminarayanan, B. (2021). Normalizing flows for probabilistic modeling and inference. https://doi.org/10.48550/arXiv.1912.02762.
9. Kingma, D. P., & Dhariwal, P. (2018). Glow: Generative flow with invertible 1x1 convolutions. https://doi.org/10.48550/arXiv.1807.03039.
10. Liu, Z., Luo, P., Wang, X., & Tang, X. (2015). Deep learning face attributes in the wild. *Proceedings of International Conference on Computer Vision (ICCV)*. Retrieved October 21, 2022, from http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html.
11. Roads, B. D., & Mozer, M. C. (2019). Obtaining psychological embeddings through joint kernel and metric learning. *Behavior Research Methods*, 51(5), 2180–2193. https://doi.org/10.3758/s13428-019-01285-3.
12. Wah, C., Branson, S., Welinder, P., Perona, P., & Belongie, S. (2011). The caltech-UCSD birds-200-2011 dataset. Retrieved August 22, 2022, from https://resolver.caltech.edu/CaltechAUTHORS:20111026-120541847.
13. He, K., Zhang, X., Ren, S., & Sun, J. (2015). Deep residual learning for image recognition. https://doi.org/10.48550/arXiv.1512.03385.
14. Dinh, L., Sohl-Dickstein, J., & Bengio, S. (2017). Density estimation using real NVP. https://doi.org/10.48550/arXiv.1605.08803.
15. Peterson, J. C., Abbott, J. T., & Griffiths, T. L. (2018). Evaluating (and improving) the correspondence between deep neural networks and human representations. *Cognitive Science*, 42(8), 2648–2669. https://doi.org/10.1111/cogs.12670.
16. Kingma, D. P., & Welling, M. (2014). Auto-encoding variational bayes. https://doi.org/10.48550/arXiv.1312.6114.
17. Attarian, M., Roads, B. D., & Mozer, M. C. (2021). Transforming neural network visual representations to predict human judgments of similarity. https://doi.org/10.48550/arXiv.2010.06512.
18. Goldstone, R. L., Medin, D. L., & Halberstadt, J. (1997). Similarity in context. *Memory & Cognition*, 25(2), 237–255. https://doi.org/10.3758/BF03201115.
